{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Old Ukrainian Morphological Parser"
      ],
      "metadata": {
        "id": "NivK87FQKgn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This ipython notebook provides a demonstration for the inference of morphological parser for Old Ukranian.\n",
        "It combines rule-based morphological parser with contextual disambiguation using fine-tuned `XLM-RoBERTa` model with custom classificator.\n"
      ],
      "metadata": {
        "id": "KFQVQQIyKpLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTpn-rl81wnB",
        "outputId": "3cf0f31d-40e6-4edc-e07f-e72ec91e7f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/dashaignatenko/old-uk-rule-based.git\n",
            "  Cloning https://github.com/dashaignatenko/old-uk-rule-based.git to /tmp/pip-req-build-jnb5hris\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dashaignatenko/old-uk-rule-based.git /tmp/pip-req-build-jnb5hris\n",
            "  Resolved https://github.com/dashaignatenko/old-uk-rule-based.git to commit 8f4f8b6522537d5114b44984467cfeb9d433a325\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyconll>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from old_uk_parser==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: fuzzywuzzy>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from old_uk_parser==0.1.0) (0.18.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from old_uk_parser==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from old_uk_parser==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: nltk>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from old_uk_parser==0.1.0) (3.9.1)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from old_uk_parser==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from old_uk_parser==0.1.0) (1.15.3)\n",
            "Requirement already satisfied: sklearn-crfsuite>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from old_uk_parser==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.8.0->old_uk_parser==0.1.0) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.8.0->old_uk_parser==0.1.0) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.8.0->old_uk_parser==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.8.0->old_uk_parser==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->old_uk_parser==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->old_uk_parser==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->old_uk_parser==0.1.0) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->old_uk_parser==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.7 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite>=0.3.6->old_uk_parser==0.1.0) (0.9.11)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite>=0.3.6->old_uk_parser==0.1.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->old_uk_parser==0.1.0) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/dashaignatenko/old-uk-rule-based.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "import pyconll\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from old_uk_parser import analyse_token, normalize_chars\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import sentencepiece"
      ],
      "metadata": {
        "id": "OMXHziGi131F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define possible morphological feature values and POS-to-feature mappings"
      ],
      "metadata": {
        "id": "t2XItVtVLx-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vocab = {\n",
        "    \"Case\": [\"Nom\", \"Acc\", \"Gen\", \"Dat\", \"Ins\", \"Loc\", \"Voc\"],\n",
        "    \"Gender\": [\"Masc\", \"Fem\", \"Neut\"],\n",
        "    \"Number\": [\"Sing\", \"Plur\", \"Dual\", \"Count\"],\n",
        "    \"Tense\": [\"Pres\", \"Past\", \"Fut\", \"\"],\n",
        "    \"Mood\": [\"Ind\", \"Imp\"],\n",
        "    \"Person\": [\"1\", \"2\", \"3\", \"\"],\n",
        "    \"Voice\": [\"Act\", \"Mid\", \"Pass\", \"\"],\n",
        "    \"VerbForm\": [\"Fin\", \"Inf\", \"Part\", \"PartRes\", \"Conv\", \"\"],\n",
        "    \"Degree\": [\"Pos\", \"Cmp\", \"Sup\"],\n",
        "    \"Variant\": [\"Full\", \"Short\"]\n",
        "}\n",
        "\n",
        "pos_features = {\n",
        "    \"NOUN\": [\"Case\", \"Gender\", \"Number\"],\n",
        "    \"PROPN\": [\"Case\", \"Gender\", \"Number\"],\n",
        "    \"VERB\": [\"Tense\", \"Mood\", \"Person\", \"Voice\", \"VerbForm\"],\n",
        "    \"ADJ\": [\"Case\", \"Gender\", \"Number\", \"Degree\", \"Variant\"]\n",
        "}\n",
        "\n",
        "label_encoders = {feature: LabelEncoder().fit(values) for feature, values in feature_vocab.items()}\n",
        "\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")"
      ],
      "metadata": {
        "id": "otW3oCek133H"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the morphological disambiguation model class\n",
        "class MorphologicalDisambiguator(nn.Module):\n",
        "    def __init__(self, feature_vocab, pos_features):\n",
        "        super(MorphologicalDisambiguator, self).__init__()\n",
        "        self.transformer = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n",
        "        self.hidden_size = self.transformer.config.hidden_size\n",
        "        self.pos_features = pos_features\n",
        "        self.analysis_encoders = nn.ModuleDict({\n",
        "            pos: nn.Linear(sum(len(feature_vocab[f]) for f in feats), self.hidden_size)\n",
        "            for pos, feats in pos_features.items()\n",
        "        })\n",
        "        self.classifiers = nn.ModuleDict({\n",
        "            pos: nn.ModuleDict({\n",
        "                feature: nn.Linear(self.hidden_size * 2, len(feature_vocab[feature]))\n",
        "                for feature in feats\n",
        "            })\n",
        "            for pos, feats in pos_features.items()\n",
        "        })\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, analysis_features, pos):\n",
        "        transformer_out = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        context_emb = transformer_out.last_hidden_state[:, 0, :]\n",
        "        analysis_emb = self.analysis_encoders[pos](analysis_features.mean(dim=1))\n",
        "        combined_emb = torch.cat([context_emb, analysis_emb], dim=-1)\n",
        "        logits = {}\n",
        "        for feature in self.pos_features[pos]:\n",
        "            logits[feature] = self.classifiers[pos][feature](combined_emb)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Pipeline inference function:\n",
        "# - Analyze each token with rule-based parser\n",
        "# - Generate feature vectors\n",
        "# - Use transformer to predict the most likely feature combination\n",
        "# - Match to the best rule-based analysis\n",
        "\n",
        "def morphological_inference(text_with_pos, model, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    results = []\n",
        "\n",
        "    for i, (word, upos) in enumerate(text_with_pos):\n",
        "        if upos not in [\"NOUN\", \"VERB\", \"ADJ\", \"PROPN\"]:\n",
        "            results.append({\n",
        "                # \"word\": word,\n",
        "                \"word\": normalize_chars(word),\n",
        "                \"pos\": upos,\n",
        "                \"analysis\": analyse_token(word, upos),\n",
        "                \"disambiguated\": None\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        context_window = 7\n",
        "        start_idx = max(0, i - context_window)\n",
        "        end_idx = min(len(text_with_pos), i + context_window + 1)\n",
        "        context = [text_with_pos[j][0] for j in range(start_idx, end_idx)]\n",
        "        target_idx = i - start_idx\n",
        "\n",
        "        context_text = \" \".join(context)\n",
        "        inputs = tokenizer(\n",
        "            context_text,\n",
        "            max_length=128,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        input_ids = inputs[\"input_ids\"].to(device)\n",
        "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "        analyses = analyse_token(word, upos)\n",
        "        if not analyses:\n",
        "            results.append({\n",
        "                \"word\": word,\n",
        "                \"pos\": upos,\n",
        "                \"analysis\": [],\n",
        "                \"disambiguated\": None\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        analysis_features = []\n",
        "        for analysis in analyses:\n",
        "            feats = analysis.get(\"features\", {})\n",
        "            one_hot = []\n",
        "            try:\n",
        "                for feature in pos_features[upos]:\n",
        "                    value_set = feats.get(feature, {''})\n",
        "                    value = next(iter(value_set)) if value_set else \"\"\n",
        "                    if upos == \"ADJ\":\n",
        "                        value = value if value else \"Pos\" if feature == \"Degree\" else \"Full\" if feature == \"Variant\" else value\n",
        "                    elif upos == \"VERB\":\n",
        "                        value = value if value else \"Ind\" if feature == \"Mood\" else value\n",
        "                    encoded = np.zeros(len(feature_vocab[feature]))\n",
        "                    if value:\n",
        "                        encoded[label_encoders[feature].transform([value])[0]] = 1\n",
        "                    one_hot.extend(encoded)\n",
        "                analysis_features.append(one_hot)\n",
        "            except ValueError as e:\n",
        "                print(f\"Skipping word '{word}' due to unseen label: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        max_analyses = 10\n",
        "        if len(analysis_features) < max_analyses:\n",
        "            analysis_features.extend([[0] * sum(len(feature_vocab[f]) for f in pos_features[upos])] * (max_analyses - len(analysis_features)))\n",
        "        else:\n",
        "            analysis_features = analysis_features[:max_analyses]\n",
        "        analysis_tensor = torch.tensor(analysis_features, dtype=torch.float).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids, attention_mask, analysis_tensor.unsqueeze(0), upos)\n",
        "\n",
        "        predicted_features = {}\n",
        "        for feature in pos_features[upos]:\n",
        "            pred_idx = torch.argmax(logits[feature], dim=1).item()\n",
        "            predicted_features[feature] = label_encoders[feature].inverse_transform([pred_idx])[0]\n",
        "\n",
        "        best_analysis = None\n",
        "        best_match_score = -1\n",
        "        for analysis in analyses:\n",
        "            analysis_feats = analysis.get(\"features\", {})\n",
        "            match_score = sum(1 for k, v in predicted_features.items() if next(iter(analysis_feats.get(k, {\"\"}))) == v)\n",
        "            if match_score > best_match_score:\n",
        "                best_match_score = match_score\n",
        "                best_analysis = analysis\n",
        "\n",
        "        results.append({\n",
        "            \"word\": word,\n",
        "            \"pos\": upos,\n",
        "            \"analysis\": analyses,\n",
        "            \"disambiguated\": {\n",
        "                \"word_form\": best_analysis[\"word_form\"],\n",
        "                \"root\": best_analysis[\"root\"],\n",
        "                \"suffix\": best_analysis[\"suffix\"],\n",
        "                \"lemma\": best_analysis[\"lemma\"],\n",
        "                \"features\": predicted_features, #выводятся предсказанные трансформером фичи\n",
        "                # альтернативно, можно выводить лучший из анализов словарно-правилового парсера\n",
        "                # \"features\": best_analysis['features'],\n",
        "                \"reflex\": best_analysis.get(\"reflex\", \"\")\n",
        "            } if best_analysis else None\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "rZ1c8SCq13-b"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(repo_id=\"dasha-ign/old_uk-disambiguation\", filename=\"old_uk_model-3105.bin\")\n",
        "config_path = hf_hub_download(repo_id=\"dasha-ign/old_uk-disambiguation\", filename=\"config.json\")\n",
        "\n",
        "model = MorphologicalDisambiguator(feature_vocab=feature_vocab, pos_features=pos_features)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lt3maTa2MbF",
        "outputId": "95ce763d-745d-4fbf-b252-edff1339a7f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MorphologicalDisambiguator(\n",
              "  (transformer): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): XLMRobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (analysis_encoders): ModuleDict(\n",
              "    (NOUN): Linear(in_features=14, out_features=768, bias=True)\n",
              "    (PROPN): Linear(in_features=14, out_features=768, bias=True)\n",
              "    (VERB): Linear(in_features=20, out_features=768, bias=True)\n",
              "    (ADJ): Linear(in_features=19, out_features=768, bias=True)\n",
              "  )\n",
              "  (classifiers): ModuleDict(\n",
              "    (NOUN): ModuleDict(\n",
              "      (Case): Linear(in_features=1536, out_features=7, bias=True)\n",
              "      (Gender): Linear(in_features=1536, out_features=3, bias=True)\n",
              "      (Number): Linear(in_features=1536, out_features=4, bias=True)\n",
              "    )\n",
              "    (PROPN): ModuleDict(\n",
              "      (Case): Linear(in_features=1536, out_features=7, bias=True)\n",
              "      (Gender): Linear(in_features=1536, out_features=3, bias=True)\n",
              "      (Number): Linear(in_features=1536, out_features=4, bias=True)\n",
              "    )\n",
              "    (VERB): ModuleDict(\n",
              "      (Tense): Linear(in_features=1536, out_features=4, bias=True)\n",
              "      (Mood): Linear(in_features=1536, out_features=2, bias=True)\n",
              "      (Person): Linear(in_features=1536, out_features=4, bias=True)\n",
              "      (Voice): Linear(in_features=1536, out_features=4, bias=True)\n",
              "      (VerbForm): Linear(in_features=1536, out_features=6, bias=True)\n",
              "    )\n",
              "    (ADJ): ModuleDict(\n",
              "      (Case): Linear(in_features=1536, out_features=7, bias=True)\n",
              "      (Gender): Linear(in_features=1536, out_features=3, bias=True)\n",
              "      (Number): Linear(in_features=1536, out_features=4, bias=True)\n",
              "      (Degree): Linear(in_features=1536, out_features=3, bias=True)\n",
              "      (Variant): Linear(in_features=1536, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplary output\n",
        "text_with_pos = [['во', 'ADP'],\n",
        "    ['имя', 'NOUN'],\n",
        "    ['отца', 'NOUN'],\n",
        "    ['и', 'CCONJ'],\n",
        "    ['сына', 'NOUN'],\n",
        "    ['и', 'CCONJ'],\n",
        "    ['святого', 'ADJ'],\n",
        "    ['духа', 'NOUN'],\n",
        "    ['.', 'PUNCT'],\n",
        "    ['аминь', 'INTJ'],\n",
        "    ['.', 'PUNCT']\n",
        "]\n",
        "\n",
        "results = morphological_inference(text_with_pos, model)\n",
        "\n",
        "for result in results:\n",
        "    print(f\"\\nWord: {result['word']}\")\n",
        "    print(f\"POS: {result['pos']}\")\n",
        "    if result['pos'] == 'PUNCT':\n",
        "        continue\n",
        "    print(\"Analyses from parser:\")\n",
        "    for analysis in result['analysis']:\n",
        "        print(f\"  {analysis}\")\n",
        "    if result['disambiguated']:\n",
        "        print(\"Disambiguated analysis:\")\n",
        "        print(f\"  {result['disambiguated']}\")\n",
        "    else:\n",
        "        print(\"No disambiguated analysis available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y06U2TOp25b_",
        "outputId": "186d07be-d56c-4706-e225-6a7468b56344"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word: во\n",
            "POS: ADP\n",
            "Analyses from parser:\n",
            "  {'word_form': 'во', 'root': 'во', 'suffix': '', 'lemma': 'во', 'features': {}}\n",
            "  {'word_form': 'во', 'root': 'во', 'suffix': '', 'lemma': 'въ', 'features': {}}\n",
            "No disambiguated analysis available.\n",
            "\n",
            "Word: имя\n",
            "POS: NOUN\n",
            "Analyses from parser:\n",
            "  {'word_form': 'имя', 'root': 'им', 'suffix': 'я', 'lemma': ['имя'], 'features': {'Case': {'Acc'}, 'Gender': {'Neut'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'имя', 'root': 'им', 'suffix': 'я', 'lemma': ['имя'], 'features': {'Case': {'Gen'}, 'Gender': {'Neut'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'имя', 'root': 'им', 'suffix': 'я', 'lemma': ['имя'], 'features': {'Case': {'Nom'}, 'Gender': {'Masc'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'имя', 'root': 'им', 'suffix': 'я', 'lemma': ['имя'], 'features': {'Case': {'Gen'}, 'Gender': {'Masc'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'имя', 'root': 'им', 'suffix': 'я', 'lemma': ['имя'], 'features': {'Case': {'Nom'}, 'Gender': {'Neut'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'имя', 'root': 'им', 'suffix': 'я', 'lemma': ['имя'], 'features': {'Case': {'Nom'}, 'Gender': {'Fem'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'имя', 'root': 'им', 'suffix': 'я', 'lemma': ['имя'], 'features': {'Case': {'Gen'}, 'Gender': {'Fem'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'имя', 'root': 'им', 'suffix': 'я', 'lemma': ['имя'], 'features': {'Case': {'Nom'}, 'Gender': {'Masc'}, 'Number': {'Plur'}}}\n",
            "  {'word_form': 'имя', 'root': 'им', 'suffix': 'я', 'lemma': ['имя'], 'features': {'Case': {'Acc'}, 'Gender': {'Masc'}, 'Number': {'Sing'}, 'Animacy': {'Anim'}}}\n",
            "Disambiguated analysis:\n",
            "  {'word_form': 'имя', 'root': 'им', 'suffix': 'я', 'lemma': ['имя'], 'features': {'Case': np.str_('Gen'), 'Gender': np.str_('Masc'), 'Number': np.str_('Sing')}, 'reflex': ''}\n",
            "\n",
            "Word: отца\n",
            "POS: NOUN\n",
            "Analyses from parser:\n",
            "  {'word_form': 'отца', 'root': 'отц', 'suffix': 'а', 'lemma': ['отецъ'], 'features': {'Case': {'Gen'}, 'Gender': {'Masc'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'отца', 'root': 'отц', 'suffix': 'а', 'lemma': ['отецъ'], 'features': {'Case': {'Acc'}, 'Gender': {'Masc'}, 'Number': {'Sing'}, 'Animacy': {'Anim'}}}\n",
            "  {'word_form': 'отца', 'root': 'отц', 'suffix': 'а', 'lemma': ['отецъ'], 'features': {'Case': {'Nom'}, 'Gender': {'Fem'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'отца', 'root': 'отц', 'suffix': 'а', 'lemma': ['отецъ'], 'features': {'Case': {'Nom'}, 'Gender': {'Masc'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'отца', 'root': 'отц', 'suffix': 'а', 'lemma': ['отецъ'], 'features': {'Case': {'Acc'}, 'Gender': {'Neut'}, 'Number': {'Plur'}}}\n",
            "  {'word_form': 'отца', 'root': 'отц', 'suffix': 'а', 'lemma': ['отецъ'], 'features': {'Case': {'Gen'}, 'Gender': {'Neut'}, 'Number': {'Sing'}}}\n",
            "Disambiguated analysis:\n",
            "  {'word_form': 'отца', 'root': 'отц', 'suffix': 'а', 'lemma': ['отецъ'], 'features': {'Case': np.str_('Gen'), 'Gender': np.str_('Masc'), 'Number': np.str_('Sing')}, 'reflex': ''}\n",
            "\n",
            "Word: и\n",
            "POS: CCONJ\n",
            "Analyses from parser:\n",
            "  {'word_form': 'и', 'root': 'и', 'suffix': '', 'lemma': 'и', 'features': {}}\n",
            "No disambiguated analysis available.\n",
            "\n",
            "Word: сына\n",
            "POS: NOUN\n",
            "Analyses from parser:\n",
            "  {'word_form': 'сына', 'root': 'сын', 'suffix': 'а', 'lemma': ['сынъ'], 'features': {'Case': {'Gen'}, 'Gender': {'Masc'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'сына', 'root': 'сын', 'suffix': 'а', 'lemma': ['сынъ'], 'features': {'Case': {'Acc'}, 'Gender': {'Masc'}, 'Number': {'Sing'}, 'Animacy': {'Anim'}}}\n",
            "  {'word_form': 'сына', 'root': 'сын', 'suffix': 'а', 'lemma': ['сынъ'], 'features': {'Case': {'Nom'}, 'Gender': {'Fem'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'сына', 'root': 'сын', 'suffix': 'а', 'lemma': ['сынъ'], 'features': {'Case': {'Nom'}, 'Gender': {'Masc'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'сына', 'root': 'сын', 'suffix': 'а', 'lemma': ['сынъ'], 'features': {'Case': {'Acc'}, 'Gender': {'Neut'}, 'Number': {'Plur'}}}\n",
            "  {'word_form': 'сына', 'root': 'сын', 'suffix': 'а', 'lemma': ['сынъ'], 'features': {'Case': {'Gen'}, 'Gender': {'Neut'}, 'Number': {'Sing'}}}\n",
            "Disambiguated analysis:\n",
            "  {'word_form': 'сына', 'root': 'сын', 'suffix': 'а', 'lemma': ['сынъ'], 'features': {'Case': np.str_('Gen'), 'Gender': np.str_('Masc'), 'Number': np.str_('Sing')}, 'reflex': ''}\n",
            "\n",
            "Word: и\n",
            "POS: CCONJ\n",
            "Analyses from parser:\n",
            "  {'word_form': 'и', 'root': 'и', 'suffix': '', 'lemma': 'и', 'features': {}}\n",
            "No disambiguated analysis available.\n",
            "\n",
            "Word: святого\n",
            "POS: ADJ\n",
            "Analyses from parser:\n",
            "  {'word_form': 'святого', 'root': 'свят', 'suffix': 'ого', 'lemma': ['святый', 'святай'], 'features': {'Case': {'Gen'}, 'Degree': {'Pos'}, 'Gender': {'Masc'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'святого', 'root': 'свят', 'suffix': 'ого', 'lemma': ['святый', 'святай'], 'features': {'Case': {'Acc'}, 'Degree': {'Pos'}, 'Gender': {'Masc'}, 'Number': {'Sing'}, 'Animacy': {'Anim'}}}\n",
            "  {'word_form': 'святого', 'root': 'свят', 'suffix': 'ого', 'lemma': ['святый', 'святай'], 'features': {'Case': {'Gen'}, 'Degree': {'Pos'}, 'Gender': {'Neut'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'святого', 'root': 'свят', 'suffix': 'ого', 'lemma': ['святый', 'святай'], 'features': {'Case': {'Gen'}, 'Degree': {'Sup'}, 'Gender': {'Masc'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'святого', 'root': 'свят', 'suffix': 'ого', 'lemma': ['святый', 'святай'], 'features': {'Case': {'Gen'}, 'Degree': {'Sup'}, 'Gender': {'Neut'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'святого', 'root': 'свят', 'suffix': 'ого', 'lemma': ['святый', 'святай'], 'features': {'Case': {'Gen'}, 'Gender': {'Masc'}, 'Number': {'Sing'}, 'NumForm': {'Word'}, 'NumType': {'Ord'}}}\n",
            "  {'word_form': 'святого', 'root': 'свят', 'suffix': 'ого', 'lemma': ['святый', 'святай'], 'features': {'Case': {'Gen'}, 'Gender': {'Neut'}, 'Number': {'Sing'}, 'NumForm': {'Word'}, 'NumType': {'Ord'}}}\n",
            "  {'word_form': 'святого', 'root': 'свят', 'suffix': 'ого', 'lemma': ['святый', 'святай'], 'features': {'Case': {'Acc'}, 'Degree': {'Sup'}, 'Gender': {'Masc'}, 'Number': {'Sing'}, 'Animacy': {'Anim'}}}\n",
            "  {'word_form': 'святого', 'root': 'святог', 'suffix': 'о', 'lemma': 'unknown', 'features': {'Case': {'Nom'}, 'Degree': {'Pos'}, 'Gender': {'Neut'}, 'Number': {'Sing'}, 'Variant': {'Short'}}}\n",
            "  {'word_form': 'святого', 'root': 'святог', 'suffix': 'о', 'lemma': 'unknown', 'features': {'Case': {'Nom'}, 'Degree': {'Pos'}, 'Gender': {'Neut'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'святого', 'root': 'святог', 'suffix': 'о', 'lemma': 'unknown', 'features': {'Case': {'Nom'}, 'Degree': {'Pos'}, 'Gender': {'Masc'}, 'Number': {'Sing'}, 'Variant': {'Short'}}}\n",
            "  {'word_form': 'святого', 'root': 'святог', 'suffix': 'о', 'lemma': 'unknown', 'features': {'Degree': {'Pos'}}}\n",
            "  {'word_form': 'святого', 'root': 'святог', 'suffix': 'о', 'lemma': 'unknown', 'features': {'Case': {'Acc'}, 'Degree': {'Pos'}, 'Gender': {'Neut'}, 'Number': {'Sing'}, 'Variant': {'Short'}}}\n",
            "Disambiguated analysis:\n",
            "  {'word_form': 'святого', 'root': 'свят', 'suffix': 'ого', 'lemma': ['святый', 'святай'], 'features': {'Case': np.str_('Gen'), 'Gender': np.str_('Masc'), 'Number': np.str_('Sing'), 'Degree': np.str_('Pos'), 'Variant': np.str_('Full')}, 'reflex': ''}\n",
            "\n",
            "Word: духа\n",
            "POS: NOUN\n",
            "Analyses from parser:\n",
            "  {'word_form': 'духа', 'root': 'дух', 'suffix': 'а', 'lemma': ['духъ'], 'features': {'Case': {'Gen'}, 'Gender': {'Masc'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'духа', 'root': 'дух', 'suffix': 'а', 'lemma': ['духъ'], 'features': {'Case': {'Acc'}, 'Gender': {'Masc'}, 'Number': {'Sing'}, 'Animacy': {'Anim'}}}\n",
            "  {'word_form': 'духа', 'root': 'дух', 'suffix': 'а', 'lemma': ['духъ'], 'features': {'Case': {'Nom'}, 'Gender': {'Fem'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'духа', 'root': 'дух', 'suffix': 'а', 'lemma': ['духъ'], 'features': {'Case': {'Nom'}, 'Gender': {'Masc'}, 'Number': {'Sing'}}}\n",
            "  {'word_form': 'духа', 'root': 'дух', 'suffix': 'а', 'lemma': ['духъ'], 'features': {'Case': {'Acc'}, 'Gender': {'Neut'}, 'Number': {'Plur'}}}\n",
            "  {'word_form': 'духа', 'root': 'дух', 'suffix': 'а', 'lemma': ['духъ'], 'features': {'Case': {'Gen'}, 'Gender': {'Neut'}, 'Number': {'Sing'}}}\n",
            "Disambiguated analysis:\n",
            "  {'word_form': 'духа', 'root': 'дух', 'suffix': 'а', 'lemma': ['духъ'], 'features': {'Case': np.str_('Gen'), 'Gender': np.str_('Masc'), 'Number': np.str_('Sing')}, 'reflex': ''}\n",
            "\n",
            "Word: .\n",
            "POS: PUNCT\n",
            "\n",
            "Word: аминь\n",
            "POS: INTJ\n",
            "Analyses from parser:\n",
            "  {'word_form': 'аминь', 'root': 'аминь', 'suffix': '', 'lemma': 'аминъ', 'features': {}}\n",
            "  {'word_form': 'аминь', 'root': 'аминь', 'suffix': '', 'lemma': 'аминь', 'features': {}}\n",
            "No disambiguated analysis available.\n",
            "\n",
            "Word: .\n",
            "POS: PUNCT\n"
          ]
        }
      ]
    }
  ]
}